{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3688983e",
   "metadata": {},
   "source": [
    "# Extraction of models from DeciContas.br Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765d459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\05911205424\\Documents\\Dev\\decicontas.br\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1784: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pymssql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain_openai import  AzureChatOpenAI, ChatOpenAI\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sqlalchemy import (\n",
    "    create_engine, Column, Integer, String, Float, Date, Boolean, Text, JSON\n",
    ")\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker, Session\n",
    "from sqlalchemy.schema import DDL, CheckConstraint\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "from tools.prompt import generate_few_shot_ner_prompts\n",
    "from tools.schema import (\n",
    "    NERDecisao,\n",
    "    Obrigacao,\n",
    "    Recomendacao,\n",
    "    \n",
    ")\n",
    "from tools.models import (\n",
    "    ObrigacaoORM, \n",
    "    RecomendacaoORM, \n",
    "    BeneficioORM, \n",
    "    NERDecisaoORM, \n",
    "    NERMultaORM, \n",
    "    NERObrigacaoORM, \n",
    "    NERRecomendacaoORM, \n",
    "    NERRessarcimentoORM,\n",
    "    EstagioBeneficio,\n",
    "    CaracteristicaBeneficio,\n",
    "    TipoBeneficio,\n",
    "    SubtipoBeneficio,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gpt4turbo = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4-turbo\",\n",
    "    model_name=\"gpt-4\",\n",
    ")\n",
    "\n",
    "'''\n",
    "gpt4turbo = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0.0\n",
    ")\n",
    "'''\n",
    "\n",
    "extractor_decisao_gpt4turbo = gpt4turbo.with_structured_output(NERDecisao, include_raw=False, method=\"json_schema\")\n",
    "extractor_obrigacao_gpt4turbo = gpt4turbo.with_structured_output(\n",
    "    Obrigacao, include_raw=False, method=\"json_schema\")\n",
    "extractor_recomendacao_gpt4turbo = gpt4turbo.with_structured_output(\n",
    "    Recomendacao, include_raw=False, method=\"json_schema\")\n",
    "\n",
    "\n",
    "def safe_int(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    return int(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c4d43",
   "metadata": {},
   "source": [
    "# Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e10e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(db: str = 'processo') -> Engine:\n",
    "    load_dotenv()\n",
    "    \n",
    "    server = os.getenv(\"SQL_SERVER_HOST\")\n",
    "    user = os.getenv(\"SQL_SERVER_USER\")\n",
    "    password = os.getenv(\"SQL_SERVER_PASS\")\n",
    "    port = os.getenv(\"SQL_SERVER_PORT\", \"1433\")  # default MSSQL port\n",
    "    database = db\n",
    "\n",
    "    # Construct connection string for SQLAlchemy using pymssql\n",
    "    connection_string = f\"mssql+pymssql://{user}:{password}@{server}/{database}\"\n",
    "\n",
    "    # Create and return SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    return engine\n",
    "\n",
    "\n",
    "def find_obrigacao_by_descricao(df_ob: pd.DataFrame, descricao: str) -> List[int]:\n",
    "    return [i for i,r in df_ob.iterrows() if descricao in r['obrigacoes'][0].descricao_obrigacao][0]\n",
    "\n",
    "def get_id_pessoa_multa_cominatoria(row, result_obrigacao) -> List[int]:\n",
    "    \"\"\"\n",
    "    Obtém o ID da pessoa responsável pela multa cominatória.\n",
    "    \"\"\"\n",
    "    if result_obrigacao.documento_responsavel_multa_cominatoria:\n",
    "        return [p['id_pessoa'] for p in row['responsaveis'] if p['documento_responsavel'] == result_obrigacao.documento_responsavel_multa_cominatoria][0]\n",
    "    return None\n",
    "\n",
    "def get_pessoas_str(pessoas: List[Dict[str, Any]]) -> str:    \n",
    "    pessoas_str = []\n",
    "    for pessoa in pessoas:\n",
    "        nome = pessoa.get('nome_responsavel', 'Desconhecido')\n",
    "        documento = pessoa.get('documento_responsavel', 'Desconhecido')\n",
    "        tipo = pessoa.get('tipo_responsavel', 'Desconhecido')\n",
    "        if tipo == 'F':\n",
    "            tipo = 'Física'\n",
    "        elif tipo == 'J':\n",
    "            tipo = 'Jurídica'\n",
    "        pessoas_str.append(f\"{nome} ({tipo} - {documento})\")\n",
    "    \n",
    "    return \", \".join(pessoas_str)\n",
    "\n",
    "# Obrigação\n",
    "\n",
    "def get_prompt_obrigacao(row: Dict[str, Any], obrigacao: Obrigacao) -> str:\n",
    "    data_sessao = row['data_sessao']\n",
    "    texto_acordao = row['texto_acordao']\n",
    "    orgao_responsavel = row['orgao_responsavel']\n",
    "    pessoas_responsaveis = row['responsaveis']\n",
    "\n",
    "\n",
    "    return f\"\"\"\n",
    "    Você é um Auditor de Controle Externo do TCE/RN. Sua tarefa é analisar o voto e extrair a obrigação imposta, preenchendo os campos do objeto Obrigacao.\n",
    "\n",
    "    Data da Sessão: {data_sessao.strftime('%d/%m/%Y')}\n",
    "    Obrigação detectada: {obrigacao.descricao_obrigacao}\n",
    "    Texto do Acordão: {texto_acordao}\n",
    "    Órgão Responsável: {orgao_responsavel}\n",
    "    Pessoas Responsáveis: {get_pessoas_str(pessoas_responsaveis)}\n",
    "\n",
    "    Dado esse contexto, preencha os campos da seguinte forma:\n",
    "    - descricao_obrigacao: Descrição da obrigação imposta.\n",
    "    - tipo: Tipo da obrigação (fazer/não fazer).\n",
    "    - prazo: Prazo estipulado para cumprimento. Extraia o texto indicando o prazo, se houver. Exemplo: \"90 dias\".\n",
    "    - data_cumprimento: Extraia do prazo do acórdão como data de início e faça o cálculo da data de cumprimento. Exemplo: 2025-09-13\n",
    "    - orgao_responsavel: Órgão responsável pelo cumprimento da obrigação. Pessoa jurídica.\n",
    "    - tem_multa_cominatoria: Indique se há multa cominatória associada à obrigação.\n",
    "    - nome_responsavel_multa_cominatoria: Nome do responsável pela obrigação, se houver multa cominatória. Pessoa física responsável.\n",
    "    - documento_responsavel_multa_cominatoria: Documento do responsável pela obrigação, se houver multa cominatória.\n",
    "    - valor_multa_cominatoria: Se houver multa cominatória, preencha o valor.\n",
    "    - periodo_multa_cominatoria: Período da multa cominatória, se houver.\n",
    "    - e_multa_cominatoria_solidaria: Indique se a multa cominatória é solidária.\n",
    "    - solidarios_multa_cominatoria: Lista de responsáveis solidários da multa cominatória.\n",
    "\n",
    "    Use somente as informações do texto do acórdão e dos dados fornecidos. Não inclua informações adicionais ou suposições.\n",
    "    Se o órgão responsável não estiver disponível, preencha o campo orgão_responsavel com \"Desconhecido\".\n",
    "    \"\"\"\n",
    "\n",
    "def extract_obrigacao(extractor: BaseChatModel, row: Dict[str, Any], obrigacao: Obrigacao) -> Obrigacao:\n",
    "    prompt_obrigacao = get_prompt_obrigacao(row, obrigacao)\n",
    "    return extractor.invoke(prompt_obrigacao)\n",
    "\n",
    "def insert_obrigacao(db_session, obrigacao: Obrigacao, row: Dict[str, Any]):\n",
    "    orm_obj = ObrigacaoORM(\n",
    "        IdProcesso=safe_int(row['id_processo']),\n",
    "        IdComposicaoPauta=safe_int(row['id_composicao_pauta']),\n",
    "        IdVotoPauta=safe_int(row['id_voto_pauta']),\n",
    "        DescricaoObrigacao=obrigacao.descricao_obrigacao,\n",
    "        DeFazer=obrigacao.de_fazer,\n",
    "        Prazo=obrigacao.prazo,\n",
    "        DataCumprimento=obrigacao.data_cumprimento,\n",
    "        OrgaoResponsavel=obrigacao.orgao_responsavel,\n",
    "        IdOrgaoResponsavel=safe_int(row['id_orgao_responsavel']),\n",
    "        TemMultaCominatoria=obrigacao.tem_multa_cominatoria,\n",
    "        NomeResponsavelMultaCominatoria=obrigacao.nome_responsavel_multa_cominatoria,\n",
    "        DocumentoResponsavelMultaCominatoria=obrigacao.documento_responsavel_multa_cominatoria,\n",
    "        IdPessoaMultaCominatoria=get_id_pessoa_multa_cominatoria(row, obrigacao),\n",
    "        ValorMultaCominatoria=obrigacao.valor_multa_cominatoria,\n",
    "        PeriodoMultaCominatoria=obrigacao.periodo_multa_cominatoria,\n",
    "        EMultaCominatoriaSolidaria=obrigacao.e_multa_cominatoria_solidaria,\n",
    "        SolidariosMultaCominatoria=obrigacao.solidarios_multa_cominatoria\n",
    "    )\n",
    "    db_session.add(orm_obj)\n",
    "    db_session.commit()\n",
    "    return orm_obj\n",
    "\n",
    "# Recomendação\n",
    "\n",
    "def get_prompt_recomendacao(row, recomendacao):\n",
    "    data_sessao = row['datasessao']\n",
    "    texto_acordao = row['texto_acordao']\n",
    "    orgao_responsavel = row['orgao_responsavel']\n",
    "    pessoas_responsaveis = row['responsaveis']\n",
    "\n",
    "\n",
    "    return f\"\"\"\n",
    "    Você é um Auditor de Controle Externo do TCE/RN. Sua tarefa é analisar o voto e extrair a recomendação feita, preenchendo os campos do objeto Recomendacao.\n",
    "\n",
    "    Data da Sessão: {data_sessao.strftime('%d/%m/%Y')}\n",
    "    Recomendação detectada: {recomendacao}\n",
    "    Texto do Acordão: {texto_acordao}\n",
    "    Órgão Responsável: {orgao_responsavel}\n",
    "    Pessoas Responsáveis: {get_pessoas_str(pessoas_responsaveis)}\n",
    "\n",
    "    Dado esse contexto, preencha os campos da seguinte forma:\n",
    "    - descricao_recomendacao: Descrição da recomendação feita.\n",
    "    - prazo_cumprimento_recomendacao: Prazo estipulado para cumprimento. Extraia o texto indicando o prazo, se houver. Exemplo: \"90 dias\".\n",
    "    - data_cumprimento_recomendacao: Extraia do prazo do acórdão como data de início e faça o cálculo da data de cumprimento. Exemplo: 2025-09-13\n",
    "    - orgao_responsavel_recomendacao: Órgão responsável pelo cumprimento da recomendação. Pessoa jurídica.\n",
    "    - nome_responsavel_recomendacao: Nome do responsável pela recomendação. Pessoa física responsável.\n",
    "\n",
    "    Use somente as informações do texto do acórdão e dos dados fornecidos. Não inclua informações adicionais ou suposições.\n",
    "    Se o órgão responsável não estiver disponível, preencha o campo orgão_responsavel com \"Desconhecido\".\n",
    "    \"\"\"\n",
    "\n",
    "def extract_recomendacao(row, recomendacao, extractor):\n",
    "    prompt_recomendacao = get_prompt_recomendacao(row, recomendacao)\n",
    "    return extractor.invoke(prompt_recomendacao)\n",
    "\n",
    "def insert_recomendacao(db_session, recomendacao: Recomendacao, row):\n",
    "    orm_obj = RecomendacaoORM(\n",
    "        IdProcesso=safe_int(row['idprocesso']),\n",
    "        IdComposicaoPauta=safe_int(row['idcomposicaopauta']),\n",
    "        IdVotoPauta=safe_int(row['idvotopauta']),\n",
    "        DescricaoRecomendacao=recomendacao.descricao_recomendacao,\n",
    "        PrazoCumprimentoRecomendacao=recomendacao.prazo_cumprimento_recomendacao,\n",
    "        DataCumprimentoRecomendacao=recomendacao.data_cumprimento_recomendacao,\n",
    "        OrgaoResponsavel=recomendacao.orgao_responsavel_recomendacao,\n",
    "        IdOrgaoResponsavel=safe_int(row['id_orgao_responsavel']),\n",
    "        NomeResponsavel=recomendacao.nome_responsavel_recomendacao\n",
    "    )\n",
    "    db_session.add(orm_obj)\n",
    "    db_session.commit()\n",
    "    return orm_obj\n",
    "\n",
    "# NER\n",
    "\n",
    "def get_decisions_by_year_and_months(ano: int, meses: List[int]):\n",
    "    sql_dec = open(\"sql/decisions_by_year_months.sql\", \"r\").read()\n",
    "    return pd.read_sql_query(sql_dec.format(ano=ano, meses=\",\".join([str(m) for m in meses])), get_connection(os.getenv(\"SQL_SERVER_DB_PROCESSOS\")))\n",
    "\n",
    "def get_decisions_by_process(process_list: List[str]):\n",
    "    sql_dec = open(\"sql/decisions_by_processes.sql\", \"r\").read()\n",
    "    return pd.read_sql_query(sql_dec.format(processes=\",\".join([f\"'{m}'\" for m in process_list])), get_connection(os.getenv(\"SQL_SERVER_DB_PROCESSOS\")))\n",
    "\n",
    "def get_ner_decision(extractor: BaseChatModel, texto_acordao: str) -> Dict[str, Any]:\n",
    "    prompt_with_few_shot = generate_few_shot_ner_prompts(texto_acordao)\n",
    "    return extractor.invoke(prompt_with_few_shot)\n",
    "\n",
    "def get_existing_ner_decision(\n",
    "    session: Session,\n",
    "    process_id: int,\n",
    "    composition_id: int,\n",
    "    vote_id: int,\n",
    ") -> Optional[NERDecisaoORM]:\n",
    "    return (\n",
    "        session.query(NERDecisaoORM)\n",
    "        .filter(\n",
    "            NERDecisaoORM.IdProcesso == process_id,\n",
    "            NERDecisaoORM.IdComposicaoPauta == composition_id,\n",
    "            NERDecisaoORM.IdVotoPauta == vote_id,\n",
    "        )\n",
    "        .one_or_none()\n",
    "    )\n",
    "\n",
    "def save_ner_decision(\n",
    "    session: Session,\n",
    "    process_id: int,\n",
    "    composition_id: int,\n",
    "    vote_id: int,\n",
    "    ner_decision: NERDecisao,  # your Pydantic model\n",
    "    model_name: Optional[str] = None,\n",
    "    prompt_version: Optional[str] = None,\n",
    "    run_id: Optional[str] = None,\n",
    ") -> int:\n",
    "    db_decision = NERDecisaoORM(\n",
    "        IdProcesso=process_id,\n",
    "        IdComposicaoPauta=composition_id,\n",
    "        IdVotoPauta=vote_id,\n",
    "        Modelo=model_name,\n",
    "        VersaoPrompt=prompt_version,\n",
    "        RunId=run_id,\n",
    "        RawJson=ner_decision.model_dump_json(),\n",
    "    )\n",
    "\n",
    "    # Multas\n",
    "    for idx, multa in enumerate(ner_decision.multas):\n",
    "        db_decision.multas.append(\n",
    "            NERMultaORM(\n",
    "                Ordem=idx,\n",
    "                DescricaoMulta=multa.descricao_multa,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Ressarcimentos\n",
    "    for idx, ressarcimento in enumerate(ner_decision.ressarcimentos):\n",
    "        db_decision.ressarcimentos.append(\n",
    "            NERRessarcimentoORM(\n",
    "                Ordem=idx,\n",
    "                DescricaoRessarcimento=ressarcimento.descricao_ressarcimento,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Obrigações\n",
    "    for idx, obrigacao in enumerate(ner_decision.obrigacoes):\n",
    "        db_decision.obrigacoes.append(\n",
    "            NERObrigacaoORM(\n",
    "                Ordem=idx,\n",
    "                DescricaoObrigacao=obrigacao.descricao_obrigacao,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Recomendações\n",
    "    for idx, recomendacao in enumerate(ner_decision.recomendacoes):\n",
    "        db_decision.recomendacoes.append(\n",
    "            NERRecomendacaoORM(\n",
    "                Ordem=idx,\n",
    "                DescricaoRecomendacao=recomendacao.descricao_recomendacao,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    session.add(db_decision)\n",
    "    session.commit()\n",
    "\n",
    "    return db_decision.IdNerDecisao\n",
    "\n",
    "import logging\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def process_decision_row(\n",
    "    session: Session,\n",
    "    row,\n",
    "    extractor: BaseChatModel,\n",
    "    model_name: str,\n",
    "    prompt_version: str,\n",
    "    run_id: str | None = None,\n",
    "    overwrite: bool = False,\n",
    ") -> int | None:\n",
    "    \"\"\"\n",
    "    Process a single decision row:\n",
    "    - Check if a NERDecisao already exists for (IdProcesso, IdComposicaoPauta, IdVotoPauta).\n",
    "    - If exists and overwrite=False, skip.\n",
    "    - If overwrite=True, delete the old one and re-run extraction.\n",
    "    - If not exists, run LLM extraction and save.\n",
    "\n",
    "    Returns:\n",
    "        IdNerDecisao or None if skipped.\n",
    "    \"\"\"\n",
    "\n",
    "    process_id = int(row.id_processo)\n",
    "    composition_id = int(row.id_composicao_pauta)\n",
    "    vote_id = int(row.id_voto_pauta)\n",
    "\n",
    "    # 1. Check for existing NER decision\n",
    "    existing = get_existing_ner_decision(\n",
    "        session=session,\n",
    "        process_id=process_id,\n",
    "        composition_id=composition_id,\n",
    "        vote_id=vote_id,\n",
    "    )\n",
    "\n",
    "    if existing and not overwrite:\n",
    "        logger.info(\n",
    "            \"Skipping NER extraction for process=%s, composition=%s, vote=%s \"\n",
    "            \"because an entry already exists (IdNerDecisao=%s).\",\n",
    "            process_id, composition_id, vote_id, existing.IdNerDecisao,\n",
    "        )\n",
    "        return existing.IdNerDecisao\n",
    "\n",
    "    if existing and overwrite:\n",
    "        logger.info(\n",
    "            \"Overwriting existing NERDecisao %s for process=%s, composition=%s, vote=%s.\",\n",
    "            existing.IdNerDecisao, process_id, composition_id, vote_id,\n",
    "        )\n",
    "        session.delete(existing)\n",
    "        session.commit()\n",
    "\n",
    "    # 2. Run NER extraction with GPT-4 Turbo (your current logic)\n",
    "    decision_text = row.texto_acordao  # adapt to the real column name\n",
    "    ner_decision = get_ner_decision(extractor, decision_text)\n",
    "\n",
    "    # 3. Save to SQL Server\n",
    "    ner_id = save_ner_decision(\n",
    "        session=session,\n",
    "        process_id=process_id,\n",
    "        composition_id=composition_id,\n",
    "        vote_id=vote_id,\n",
    "        ner_decision=ner_decision,\n",
    "        model_name=model_name,\n",
    "        prompt_version=prompt_version,\n",
    "        run_id=run_id,\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        \"Saved NERDecisao IdNerDecisao=%s for process=%s, composition=%s, vote=%s.\",\n",
    "        ner_id, process_id, composition_id, vote_id,\n",
    "    )\n",
    "\n",
    "    return ner_id\n",
    "\n",
    "def run_ner_pipeline_for_dataframe(df, extractor: BaseChatModel, model_name: str, prompt_version: str, run_id: str | None = None):\n",
    "    engine = get_connection(os.getenv(\"SQL_SERVER_DB_DECISOES\"))\n",
    "    SessionLocal = sessionmaker(bind=engine)\n",
    "    session = SessionLocal()\n",
    "    try:\n",
    "        for _, row in df.iterrows():\n",
    "            process_decision_row(\n",
    "                session=session,\n",
    "                row=row,\n",
    "                extractor=extractor,\n",
    "                model_name=model_name,\n",
    "                prompt_version=prompt_version,\n",
    "                run_id=run_id,\n",
    "                overwrite=False,  # set to True if you want to reprocess\n",
    "            )\n",
    "    finally:\n",
    "        session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda52b7",
   "metadata": {},
   "source": [
    "# Run for year and months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9449b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dec_2025_1 = get_decisions_by_year_and_months(2025, [10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c44d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ner_pipeline_for_dataframe(\n",
    "    df=df_dec_2025_1,\n",
    "    extractor=extractor_decisao_gpt4turbo,\n",
    "    model_name=\"gpt-4-turbo\",\n",
    "    prompt_version=\"v1\",\n",
    "    run_id=datetime.now().strftime(\"Extração NER %d/%m/%Y %H:%M:%S\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be68bd",
   "metadata": {},
   "source": [
    "# Run for processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc840554",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ['002039/2020',\n",
    "'200008/2023',\n",
    "'009819/2016',\n",
    "'000294/2024',\n",
    "'004102/2021',\n",
    "'004478/2021',\n",
    "'101152/2021',\n",
    "'000066/2021',\n",
    "'006828/2015',\n",
    "'004703/2024',\n",
    "'000244/2025',\n",
    "'006347/2014',\n",
    "'000664/2024',\n",
    "'005234/2020',\n",
    "'100603/2020',\n",
    "'101069/2022',\n",
    "'101081/2022',\n",
    "'200243/2021',\n",
    "'200166/2021',\n",
    "'002020/2020',\n",
    "'006590/2015',\n",
    "'003131/2024',\n",
    "'100854/2020',\n",
    "'100008/2021',\n",
    "'100584/2020',\n",
    "'100612/2020',\n",
    "'100708/2020',\n",
    "'100726/2020',\n",
    "'101060/2022',\n",
    "'100604/2020',\n",
    "'101640/2019',\n",
    "'100889/2020',\n",
    "'002347/2023',\n",
    "'002490/2020',\n",
    "'200018/2023',\n",
    "'003127/2024',\n",
    "'101162/2022',\n",
    "'100537/2020',\n",
    "'100177/2020',\n",
    "'100231/2021',\n",
    "'100356/2020',\n",
    "'100736/2022',\n",
    "'102457/2021',\n",
    "'100416/2020',\n",
    "'100462/2020',\n",
    "'100504/2020',\n",
    "'100602/2020',\n",
    "'100926/2020',\n",
    "'001992/2020',\n",
    "'002370/2020',\n",
    "'100426/2020',\n",
    "'100475/2020',\n",
    "'100484/2020',\n",
    "'100495/2020',\n",
    "'100501/2020',\n",
    "'100613/2020',\n",
    "'100615/2020',\n",
    "'001605/2025',\n",
    "'006160/2014',\n",
    "'006496/2015',\n",
    "'002153/2020',\n",
    "'302904/2023',\n",
    "'010680/2014',\n",
    "'006334/2015',\n",
    "'200034/2021',\n",
    "'024971/2016',\n",
    "'006040/2014',\n",
    "'600229/2020',\n",
    "'004339/2019',\n",
    "'003136/2024',\n",
    "'015898/2013',\n",
    "'006620/2015',\n",
    "'006444/2015',\n",
    "'005848/2014',\n",
    "'002695/2020',\n",
    "'001989/2020',\n",
    "'006375/2015',\n",
    "'006650/2015',\n",
    "'101072/2022',\n",
    "'101539/2021',\n",
    "'007970/2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c12ca0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processes = get_decisions_by_process(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ec1d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ner_pipeline_for_dataframe(\n",
    "    df=df_processes,\n",
    "    extractor=extractor_decisao_gpt4turbo,\n",
    "    model_name=\"gpt-4-turbo\",\n",
    "    prompt_version=\"v1\",\n",
    "    run_id=datetime.now().strftime(\"Extração NER %d/%m/%Y %H:%M:%S\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5e8f7",
   "metadata": {},
   "source": [
    "# Obrigacao and Recomendacao Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a357530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113369e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca9f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc22524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6532e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a4b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df92b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
